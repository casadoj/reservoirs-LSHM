{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4516f5e0-f0dd-4bdb-af93-3cf34cfb94c6",
   "metadata": {},
   "source": [
    "# ResOpsPT: time series\n",
    "***\n",
    "\n",
    "**Autor:** Chus Casado<br>\n",
    "**Date:** 04-04-2025<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This code creates the time series for the reservoirs in ResOpsPT. The time series include records from CONAGUA and simulations from GloFAS. The result is a time series that combines the observed data from CONAGUA with the simulation from GloFASv4. For each reservoir, these time series are exported both in CSV and a NetCDF format.\n",
    "\n",
    "Records are cleaned to avoid errors:\n",
    "\n",
    "* Outliers in the **storage** time series are filtered by comparison with a moving median (window 7 days). If the relative difference of a given storage value and the moving median exceeds a threshold, the value is removed. This procedure is encapsulated in the function `reservoirs_lshm.utils.timeseries.clean_storage()`\n",
    "* Outliers in the **inflow** time series are removed using two conditions: one based in the gradient, and the other using an estimated inflow based on the water balance. When both conditions are met, the value is removed. Since inflow time series cannot contain missing values when used in the reservoir simulation, a simple linear interpolation is used to fill in gaps up to 7 days. This procedure is encapsulated in the function `reservoirs_lshm.utils.timeseries.clean_inflow()`.\n",
    "\n",
    "**To do:**<br>\n",
    "* [ ] 8 reservoirs that should be in GloFAS don't have time series.\n",
    "* [ ] Plot time series\n",
    "* [ ] Make sure that there aren't negative values in the time series, nor zeros in storage.\n",
    "* [ ] Check the quality of the data by closing the mass balance when possible. <font color='steelblue'>I've used the mass balance to identify errors in the inflow time series (function `clean_inflow`).</font>.\n",
    "* [ ] Fill in the inflow time series with the mass balance, if possible. <font color='steelblue'>I've filled in gaps in the inflow time series with linear interpolation up to 7-day gaps (function `clean_inflow`).</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f56e74-ae31-4b60-be69-fc127719c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "# from datetime import datetime, timedelta\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from reservoirs_lshm.utils import DatasetConfig\n",
    "from reservoirs_lshm import read_attributes\n",
    "# from reservoirs_lshm.utils.plots import plot_resops, reservoir_analysis, compare_flows\n",
    "from reservoirs_lshm.utils.timeseries import time_encoding, clean_storage, clean_inflow, quantile_mapping\n",
    "\n",
    "from utils_pt import fit_reservoir_curve, plot_timeseries_PT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c16a79-1c1c-42d0-8b03-11e6ece2dfb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9034a7b1-74d9-47ea-8457-7f748a3eb4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series will be saved in Z:\\nahaUsers\\casadje\\datasets\\reservoirs\\ResOpsPT\\v1.0\\time_series\n"
     ]
    }
   ],
   "source": [
    "cfg = DatasetConfig('config_dataset.yml')\n",
    "\n",
    "PATH_METEO = cfg.PATH_RESOPS / 'ancillary' / 'catchstats'\n",
    "PATH_PLOTS = cfg.PATH_TS / 'plots'\n",
    "PATH_PLOTS.mkdir(exist_ok=True)\n",
    "\n",
    "print(f'Time series will be saved in {cfg.PATH_TS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f351856-cee6-4d5e-b561-724f4ea6ebb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data\n",
    "\n",
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65d097c-12e8-4885-81c7-506b1d2f91c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 stations selected\n"
     ]
    }
   ],
   "source": [
    "# load reservoir shapefile\n",
    "reservoirs = gpd.read_file(cfg.PATH_RESOPS / 'GIS' / 'reservoirs_HDMS+GRAND.shp')\n",
    "# remove those without associated GRanD ID\n",
    "reservoirs = reservoirs[reservoirs.GRAND_ID.notnull()]\n",
    "reservoirs.GRAND_ID = reservoirs.GRAND_ID.astype(int)\n",
    "reservoirs.set_index('GRAND_ID', drop=True, inplace=True)\n",
    "\n",
    "print(f'{len(reservoirs)} stations selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cbf891-79d3-4317-9964-b99f1df92649",
   "metadata": {},
   "source": [
    "### Attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174962b2-194f-4e4b-a97c-825c179fef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 reservoirs in the attribute tables\n"
     ]
    }
   ],
   "source": [
    "# import all tables of attributes\n",
    "attributes = read_attributes(cfg.PATH_ATTRS)\n",
    "print(f'{attributes.shape[0]} reservoirs in the attribute tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1228fdc-7588-4e0f-ad5e-25b95df3412a",
   "metadata": {},
   "source": [
    "### Time series\n",
    "#### HDMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616ad90f-199d-456f-99b5-4886a57f4645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f175026028c47bfab942728e5a16181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "load timeseries:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timeseries = {}\n",
    "for grand_id, efas_id in tqdm(reservoirs.EFAS_ID.items(), total=len(reservoirs), desc='load timeseries'):\n",
    "\n",
    "    file = cfg.PATH_OBS_TS / f'{efas_id}.csv'\n",
    "    if file.is_file():\n",
    "\n",
    "        ts = pd.read_csv(file, parse_dates=['time'], index_col='time')\n",
    "\n",
    "        # remove negative values\n",
    "        ts[ts < 0] = np.nan\n",
    "        \n",
    "        # clean outliers in storage\n",
    "        if 'storage' in ts.columns:\n",
    "            ts.storage /= 1000 # convert to hm3\n",
    "            clean_storage(ts.storage, w=7, error_thr=.1, inplace=True)\n",
    "\n",
    "        # clean inflow time series\n",
    "        if 'inflow' in ts.columns:\n",
    "            clean_inflow(\n",
    "                ts.inflow,\n",
    "                storage=ts.storage if 'storage' in ts.columns else None,\n",
    "                outlfow=ts.outflow if 'outflow' in ts.columns else None,\n",
    "                grad_thr=1e4,\n",
    "                balance_thr=5,\n",
    "                int_method='linear',\n",
    "                inplace=True\n",
    "            )\n",
    "\n",
    "        # trim time series to period with inflow, storage and outflow\n",
    "        start, end = max(cfg.START, ts.first_valid_index()), min(cfg.END, ts.last_valid_index())\n",
    "        attributes.loc[grand_id, ['TIME_SERIES_START', 'TIME_SERIES_END']] = start, end\n",
    "        ts = ts.loc[start:end]\n",
    "        \n",
    "        # save\n",
    "        timeseries[grand_id] = ts.loc[start:end]\n",
    "    else:\n",
    "        print(f'File not found: {file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6526d61-6aab-4696-80ee-7fb74548378b",
   "metadata": {},
   "source": [
    "##### **Plot timeseries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b31b21f-c108-4129-9faa-0c5383a8c3ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee82de4b8df4b9a82f923f62752bc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for grand_id, ts in tqdm(timeseries.items()):\n",
    "    title = '{0} - {1}'.format(grand_id, attributes.loc[grand_id, 'DAM_NAME'])\n",
    "    plot_timeseries_PT(\n",
    "        storage=ts.storage if 'storage' in ts.columns else None,\n",
    "        elevation=ts.elevation if 'elevation' in ts.columns else None,\n",
    "        inflow=ts.inflow if 'inflow' in ts.columns else None,\n",
    "        outflow=ts.outflow if 'outflow' in ts.columns else None,\n",
    "        max_storage={'GRanD': attributes.loc[grand_id, 'CAP_MCM']},\n",
    "        max_elevation={'GRanD': attributes.loc[grand_id, 'ELEV_MASL']},\n",
    "        title=title,\n",
    "        save=PATH_PLOTS / f'{grand_id}.jpg'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c53eb1d-d35c-4c92-aedd-79f966374e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert to xarray.Dataset\n",
    "xarray_list = []\n",
    "for key, df in timeseries.items():\n",
    "    ds = xr.Dataset.from_dataframe(df)\n",
    "    ds = ds.assign_coords(GRAND_ID=key)\n",
    "    xarray_list.append(ds)\n",
    "obs = xr.concat(xarray_list, dim='GRAND_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c98ca-b485-44de-aa1a-3ffd79dad967",
   "metadata": {},
   "source": [
    "#### EFAS\n",
    "\n",
    "##### Inflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c492b695-3c5d-4444-b7ce-353b4198bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GloFAS simulation\n",
    "sim = xr.open_mfdataset(cfg.PATH_SIM_TS.glob('*.nc')).compute()\n",
    "sim = sim.rename({'time': 'date', 'id': 'GRAND_ID', 'dis': 'inflow'})\n",
    "sim = sim.drop_vars(['surface', 'latitude', 'longitude', 'lat', 'lon'], errors='ignore')\n",
    "sim['date'] = sim['date'] - pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a369b5f-6272-40a9-b989-d5e913473850",
   "metadata": {},
   "source": [
    "##### Meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff672bce-238c-451b-9f25-b2d8f2fafde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load meteorological time series\n",
    "path_meteo_areal = cfg.PATH_RESOPS / 'ancillary' / 'catchstats'\n",
    "variables = [x.stem for x in path_meteo_areal.iterdir() if x.is_dir()]\n",
    "meteo_areal = xr.Dataset({f'{var}': xr.open_mfdataset(f'{path_meteo_areal}/{var}/*.nc')[f'{var}_mean'].compute() for var in variables})\n",
    "meteo_areal['time'] = meteo_areal['time'] - pd.Timedelta(days=1)\n",
    "\n",
    "# keep catchments in the attributes\n",
    "IDs = list(attributes.index.intersection(meteo_areal.id.data))\n",
    "meteo_areal = meteo_areal.sel(id=IDs)\n",
    "\n",
    "# rename 'id' with the GRanD ID\n",
    "meteo_areal = meteo_areal.rename({\n",
    "    'id': 'GRAND_ID',\n",
    "    'time': 'date',\n",
    "    'e0': 'evapo_areal',\n",
    "    'pr': 'precip_areal',\n",
    "    'ta': 'temp_areal'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5c32d-83b3-4747-a327-bdbd20417914",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "### Convert units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2303dbdc-84b2-4b23-92c5-8a1d674691d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.NORMALIZE:\n",
    "\n",
    "    # reservoir attributes used to normalize the dataset\n",
    "    area_sm = xr.DataArray.from_series(attributes.AREA_SKM) * 1e6 # m2\n",
    "    capacity_cm = xr.DataArray.from_series(attributes.CAP_MCM) * 1e6 # m3\n",
    "    catchment_sm = xr.DataArray.from_series(attributes.CATCH_SKM) * 1e6 # m2\n",
    "    \n",
    "    # Observed timeseries\n",
    "    # -------------------\n",
    "    for var, da in obs.items():\n",
    "        # convert variables in hm3 to fraction of reservoir capacity [-]\n",
    "        if var in ['storage', 'evaporation']:\n",
    "            obs[f'{var}_norm'] = obs[var] * 1e6 / capacity_cm\n",
    "        # convert variables in m3/s to fraction of reservoir capacity [-]\n",
    "        elif var in ['inflow', 'outflow']:\n",
    "            obs[f'{var}_norm'] = obs[var] * 24 * 3600 / capacity_cm\n",
    "\n",
    "    # Simulated timeseries\n",
    "    # -------------------\n",
    "    for var, da in sim.items():\n",
    "        # convert variables in hm3 to fraction of reservoir capacity [-]\n",
    "        if var.split('_')[0] in ['storage']:\n",
    "            sim[f'{var}_norm'] = sim[var] * 1e6 / capacity_cm\n",
    "        # convert variables in m3/s to fraction of reservoir capacity [-]\n",
    "        elif var.split('_')[0] in ['inflow', 'outflow']:\n",
    "            sim[f'{var}_norm'] = sim[var] * 24 * 3600 / capacity_cm\n",
    "            \n",
    "    # Catchment meteorology\n",
    "    # ---------------------\n",
    "    # convert areal evaporation and precipitation from mm to fraction filled\n",
    "    for var in ['evapo', 'precip']:\n",
    "        meteo_areal[f'{var}_areal_norm'] = meteo_areal[f'{var}_areal'] * catchment_sm * 1e-3 / capacity_cm       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed75f2-62e4-442e-b897-52dee820581e",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87f7ec-3b05-4d48-978f-a3bb8ad140a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_csv = cfg.PATH_TS / 'csv'\n",
    "path_csv.mkdir(parents=True, exist_ok=True)\n",
    "path_nc = cfg.PATH_TS / 'netcdf'\n",
    "path_nc.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for grand_id in tqdm(attributes.index, desc='Exporting time series'):\n",
    "\n",
    "    # concatenate time series\n",
    "    ds = obs.sel(GRAND_ID=grand_id).drop(['GRAND_ID'])\n",
    "    if grand_id in sim.GRAND_ID.data:\n",
    "        ds = xr.merge((ds, sim.sel(GRAND_ID=grand_id).drop(['GRAND_ID'])))\n",
    "    if grand_id in meteo_areal.GRAND_ID.data:\n",
    "        ds = xr.merge((ds, meteo_areal.sel(GRAND_ID=grand_id).drop(['GRAND_ID'])))\n",
    "\n",
    "    # # delete empty variables\n",
    "    # for var in list(ds.data_vars):\n",
    "    #     if (ds[var].isnull().all()):\n",
    "    #         del ds[var]\n",
    "        \n",
    "    # trim time series to the observed period\n",
    "    start, end = attributes.loc[grand_id, ['TIME_SERIES_START', 'TIME_SERIES_END']]\n",
    "    ds = ds.sel(date=slice(start, end))\n",
    "\n",
    "#     # create time series of temporal attributes\n",
    "#     ds['year'] = ds.date.dt.year\n",
    "#     ds['month'] = ds.date.dt.month\n",
    "#     ds['month_sin'], ds['month_cos'] = time_encoding(ds['month'], period=12)\n",
    "#     ds['weekofyear'] = ds.date.dt.isocalendar().week\n",
    "#     ds['woy_sin'], ds['woy_cos'] = time_encoding(ds['weekofyear'], period=52)\n",
    "#     ds['dayofyear'] = ds.date.dt.dayofyear\n",
    "#     ds['doy_sin'], ds['doy_cos'] = time_encoding(ds['dayofyear'], period=365)\n",
    "#     ds['dayofweek'] = ds.date.dt.dayofweek\n",
    "#     ds['dow_sin'], ds['dow_cos'] = time_encoding(ds['dayofweek'], period=6)\n",
    "\n",
    "#     # export CSV\n",
    "#     # ..........\n",
    "#     ds.to_pandas().to_csv(path_csv / f'{grand_id}.csv')\n",
    "\n",
    "#     # export NetCDF\n",
    "#     # .............\n",
    "#     ds.to_netcdf(path_nc / f'{grand_id}.nc')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f36e6-810f-4e10-af68-bc90769ace80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
