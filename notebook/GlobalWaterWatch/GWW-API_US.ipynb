{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a635f097-5d2a-48f0-8862-5668bd467010",
   "metadata": {},
   "source": [
    "# Global Water Watch - US\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f3e730-df0d-488a-b0db-6c44e626ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from gwwapi.client import get_tiled_reservoirs, get_reservoir_ts\n",
    "from gwwapi.utils import to_timeseries, to_geopandas, plot_reservoir_timeseries\n",
    "\n",
    "from lisfloodreservoirs import read_attributes, read_timeseries\n",
    "from lisfloodreservoirs.utils.reservoir_curves import bin_data, fit_reservoir_curve, storage_from_elevation, area_from_elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd11a7",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e73e9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'US'\n",
    "long_name = 'United States'\n",
    "extent = [-125, 24, -66, 50]\n",
    "\n",
    "path_datasets = Path('/home/chus-casado/Datos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40324b2",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83147b4f",
   "metadata": {},
   "source": [
    "### ResOpsUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1f8e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24504e1ac95448e0befa1fc33b9aee28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series for ID 55 is missing variables: {'elevation'}\n",
      "Time series for ID 57 is missing variables: {'elevation'}\n",
      "Time series for ID 60 is missing variables: {'elevation'}\n",
      "Time series for ID 63 is missing variables: {'elevation'}\n",
      "Time series for ID 131 is missing variables: {'elevation'}\n",
      "Time series for ID 132 is missing variables: {'elevation'}\n",
      "Time series for ID 133 is missing variables: {'elevation'}\n",
      "Time series for ID 148 is missing variables: {'elevation'}\n",
      "Time series for ID 180 is missing variables: {'elevation'}\n",
      "Time series for ID 191 is missing variables: {'elevation'}\n",
      "Time series for ID 193 is missing variables: {'elevation'}\n",
      "Time series for ID 198 is missing variables: {'elevation'}\n",
      "Time series for ID 214 is missing variables: {'elevation'}\n",
      "Time series for ID 297 is missing variables: {'elevation'}\n",
      "Time series for ID 361 is missing variables: {'elevation'}\n",
      "Time series for ID 367 is missing variables: {'elevation'}\n",
      "Time series for ID 372 is missing variables: {'elevation'}\n",
      "Time series for ID 384 is missing variables: {'elevation'}\n",
      "Time series for ID 390 is missing variables: {'elevation'}\n",
      "Time series for ID 391 is missing variables: {'elevation'}\n",
      "Time series for ID 530 is missing variables: {'elevation'}\n",
      "Time series for ID 595 is missing variables: {'elevation'}\n",
      "Time series for ID 600 is missing variables: {'elevation'}\n",
      "Time series for ID 612 is missing variables: {'elevation'}\n",
      "Time series for ID 620 is missing variables: {'elevation'}\n",
      "Time series for ID 1192 is missing variables: {'elevation'}\n"
     ]
    }
   ],
   "source": [
    "path_resops = path_datasets / 'reservoirs' / 'ResOpsUS' / 'v2.2'\n",
    "\n",
    "# list of selected reservoirs\n",
    "res_list = pd.read_csv(path_resops / 'selection' / 'reservoirs.txt', header=None).squeeze().tolist()\n",
    "\n",
    "# load reservoir attributes\n",
    "resops_attrs = read_attributes(\n",
    "    path=path_resops / 'attributes',\n",
    "    reservoirs=res_list,\n",
    "    index_col='GRAND_ID'\n",
    ")\n",
    "\n",
    "# load time series\n",
    "resops_ts = read_timeseries(\n",
    "    path=path_resops / 'time_series' / 'csv',\n",
    "    reservoirs=resops_attrs.index,\n",
    "    variables=['inflow', 'outflow', 'storage', 'elevation']\n",
    ")\n",
    "# convert storage units to hm3\n",
    "for grand_id, df in resops_ts.items():\n",
    "    if 'storage' in df.columns:\n",
    "        df.storage *= 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564294d3",
   "metadata": {},
   "source": [
    "### Global Dam Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4eb4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDW contains 4862 reservoirs in United States\n",
      "164 are both in GDW and ResOps datasets\n"
     ]
    }
   ],
   "source": [
    "path_gdw = path_datasets / 'reservoirs' / 'GDW' / 'GDW_v1_0_shp'\n",
    "gdw = gpd.read_file(path_gdw / 'GDW_barriers_v1_0.shp').set_index('GRAND_ID')\n",
    "gdw = gdw[gdw.COUNTRY == long_name]\n",
    "print(f'GDW contains {len(gdw)} reservoirs in {long_name}')\n",
    "\n",
    "# reduce reservoirs to those in both GDW and ResOps datasets\n",
    "grand_ids = gdw.index.intersection(resops_ts.keys())\n",
    "gdw = gdw.loc[grand_ids]\n",
    "resops_ts = {grand_id: resops_ts[grand_id] for grand_id in grand_ids}\n",
    "print(f'{len(grand_ids)} are both in GDW and ResOps datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01663dc9-582f-43db-99a3-6d47b80e8e3b",
   "metadata": {},
   "source": [
    "### Global Water Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fec12c45-18db-4266-ba49-613f544145c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gww = path_datasets / 'reservoirs' / 'GWW'\n",
    "path_gww_gis = path_gww / 'GIS'\n",
    "path_gww_ts = path_gww / 'time_series' / 'raw'\n",
    "path_gww_plots = path_gww_ts / 'plots'\n",
    "path_gww_plots.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53717ec5-faeb-459d-a59a-e2e83ab3b3e4",
   "metadata": {},
   "source": [
    "#### Attributes\n",
    "This bit extracts all the reservoir instances in the GWW database within a bounding box. The resulting list of JSONs is then converted into a `geopandas.GeoDataFrame` of polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb01a3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679 reservoirs loaded from /home/chus-casado/Datos/reservoirs/GWW/GIS/gww_US.shp\n"
     ]
    }
   ],
   "source": [
    "# shapefile of GWW reservoirs\n",
    "gww_shp = path_gww_gis / f'gww_{country}.shp'\n",
    "\n",
    "if gww_shp.is_file():\n",
    "    # import reservoirs\n",
    "    gww_attrs = gpd.read_file(gww_shp).set_index('grand_id')\n",
    "    print(f'{len(gww_attrs)} reservoirs loaded from {gww_shp}')\n",
    "else:\n",
    "    # get reservoir features from GWW in the US\n",
    "    features = get_tiled_reservoirs(*extent)\n",
    "\n",
    "    # convert to GeoPandas\n",
    "    gww_attrs = to_geopandas(features)\n",
    "    gww_attrs.drop_duplicates(inplace=True)\n",
    "    gww_attrs.rename(columns={'source_name': 'source'}, inplace=True)\n",
    "    print(f'{len(gww_attrs)} reservoirs within the extent')\n",
    "\n",
    "    # find those in GRanD\n",
    "    in_grand = gww_attrs.grand_id.isin(gdw.index)\n",
    "    gww_attrs = gww_attrs[in_grand]\n",
    "    print(f'{in_grand.sum()} of those reservoirs are in {long_name} and have a GRanD ID assigned')\n",
    "\n",
    "    # export those with GRanD ID\n",
    "    gww_attrs.to_file(gww_shp)\n",
    "    print(f'Shapefile saved to {gww_shp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adabd728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 are both in GWW and ResOps datasets\n"
     ]
    }
   ],
   "source": [
    "# reduce reservoirs to those in both ResOps\n",
    "grand_ids = gww_attrs.index.intersection(resops_ts.keys())\n",
    "gww_attrs = gww_attrs.loc[grand_ids]\n",
    "resops_ts = {grand_id: resops_ts[grand_id] for grand_id in grand_ids}\n",
    "print(f'{len(grand_ids)} are both in GWW and ResOps datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6185dd-dcbe-45a5-8c82-92bcaeea6485",
   "metadata": {},
   "source": [
    "#### Time series \n",
    "This snippet extracts time series from the GWW database. It searches for available time series of reservoir area and volume, saves them in a dictionary and exports it as CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4731b34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191283ce527c462a848bb70d54416da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple intances of GRanD ID 1033 in GWW\n",
      "Multiple intances of GRanD ID 597 in GWW\n",
      "Multiple intances of GRanD ID 1207 in GWW\n",
      "Multiple intances of GRanD ID 1796 in GWW\n",
      "Multiple intances of GRanD ID 1872 in GWW\n",
      "Multiple intances of GRanD ID 870 in GWW\n",
      "Multiple intances of GRanD ID 989 in GWW\n"
     ]
    }
   ],
   "source": [
    "# download/import time series\n",
    "gww_ts = {}\n",
    "for grand_id in tqdm(set(gww_attrs.index)):\n",
    "    try:\n",
    "        gww_id = gww_attrs.loc[grand_id, 'gww_id'].item()\n",
    "    except:\n",
    "        print(f'Multiple intances of GRanD ID {grand_id} in GWW')\n",
    "        continue\n",
    "\n",
    "    csv_file = path_gww_ts / f'{gww_id}.csv'\n",
    "    if csv_file.is_file():\n",
    "        # import time series from CSV\n",
    "        gww_ts[grand_id] = pd.read_csv(csv_file, parse_dates=True, index_col=0)\n",
    "        continue\n",
    "    \n",
    "    # download time series from GWW\n",
    "    ts = []\n",
    "    for variable in ['area', 'volume']:\n",
    "        data = get_reservoir_ts(\n",
    "            reservoir_id=gww_id,\n",
    "            start=datetime(1975, 1, 1),\n",
    "            stop=datetime(2025, 9, 30),\n",
    "            variable=variable\n",
    "        )\n",
    "        if len(data) > 0:\n",
    "            ts.append(to_timeseries(data, convert_units=True))\n",
    "    if len(ts) == 0:\n",
    "        print(f'No time series found for GRanD ID {grand_id}')\n",
    "        continue\n",
    "    gww_ts[grand_id] = pd.concat(ts, axis=1)\n",
    "    \n",
    "    # export as CSV\n",
    "    gww_ts[grand_id].to_csv(csv_file, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef96172",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Compare ResOps with GWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "900dc704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dba7a71d9d5432bb887fde088a363bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for grand_id, ts in tqdm(gww_ts.items(), total=len(gww_ts)):\n",
    "    gww_id = gww_attrs.loc[grand_id, 'gww_id'].item()\n",
    "    plot_reservoir_timeseries(\n",
    "        reservoir=gww_attrs.loc[[grand_id]],\n",
    "        gww_area=ts.area_skm,\n",
    "        gww_vol=ts.volume_mcm if 'volume_mcm' in ts else None,\n",
    "        obs_vol=resops_ts[grand_id].storage if 'storage' in resops_ts[grand_id] else None,\n",
    "        ref_area=gdw.loc[grand_id, 'AREA_SKM'],\n",
    "        ref_vol=gdw.loc[grand_id, 'CAP_MCM'],\n",
    "        ref_label='GDW',\n",
    "        title='GRanD {0} - {1} ({2})'.format(grand_id, *gdw.loc[grand_id, ['DAM_NAME', 'COUNTRY']]),\n",
    "        save=path_gww_ts / 'plots' / f'{gww_id}.jpg'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reservoirs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
