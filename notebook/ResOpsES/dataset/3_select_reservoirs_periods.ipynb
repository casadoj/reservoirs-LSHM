{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631e1812-9c8c-4f8e-ad1b-41578130117b",
   "metadata": {},
   "source": [
    "# Select reservoirs and study period\n",
    "***\n",
    "\n",
    "**Author:** Chus Casado Rodríguez<br>\n",
    "**Date:** 05-09-2024<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This notebook reads all the attributes and time series in the dataset and selects the reservoirs appropriate for testing the different reservoir routines. Several conditions need to be met for a reservoir to be selected:\n",
    "\n",
    "1. It must contain observed time series of the variables `inflow`, `storage` and `outflow`. <font color='red'>NOT IN RESOPSES!!!</font>\n",
    "2. The longest period without gaps in those three time series needs to be longer than 8 years.\n",
    "3. The bias between the observed inflow and outflow timeseries needs to be between 0.7 and 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1940f88-25de-47e5-88ec-2ba55e079da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\casadje\\AppData\\Local\\Temp\\ipykernel_6212\\3723810648.py:7: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from reservoirs_lshm import read_attributes, read_timeseries\n",
    "from reservoirs_lshm.utils import DatasetConfig\n",
    "from reservoirs_lshm.utils.timeseries import define_period #,create_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d503d3-dd70-4b64-b148-ff7f86e0b789",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0c696d1-6723-4c46-b84b-94e978d70e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected reservoirs and periods will be saved in:\n",
      "\tZ:\\nahaUsers\\casadje\\datasets\\reservoirs\\ResOpsES\\v3.0\\selection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = DatasetConfig('config_dataset.yml')\n",
    "\n",
    "PATH_OUT = cfg.PATH_RESOPS / cfg.VERSION / 'selection'\n",
    "PATH_OUT.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Selected reservoirs and periods will be saved in:\\n\\t{PATH_OUT}\\n')\n",
    "\n",
    "variables = ['inflow', 'storage', 'outflow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da057a63-1f1b-412b-9188-3b984c86a637",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab25ee-79ef-423a-aaf5-eb3c10fc6d6a",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f3767b-5d97-442c-ac6c-d52ebd123d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 reservoirs in the attribute tables\n",
      "207 reservoirs comply with the minimum catchment area: 25 km²\n",
      "207 reservoirs comply with the minimum storage capacity: 10 hm3\n",
      "178 reservoirs comply with the minimum degree of regulation: 0.08\n",
      "145 reservoirs comply with the minimum degree of disruptivity: 0.06 m\n"
     ]
    }
   ],
   "source": [
    "# import all tables of attributes\n",
    "attributes = pd.read_csv(cfg.PATH_ATTRS / 'combined.csv', index_col='GRAND_ID') #read_attributes(PATH_DATA / 'attributes', reservoirs=None)\n",
    "print(f'{attributes.shape[0]} reservoirs in the attribute tables')\n",
    "\n",
    "# # keep only reservoirs with all observed variables\n",
    "# mask = pd.concat([attributes[var.upper()] == 1 for var in variables], axis=1).all(axis=1)\n",
    "# attributes = attributes[mask]\n",
    "# attributes.sort_index(axis=0, inplace=True)\n",
    "# print('{0} reservoirs include observed time series for all variables: {1}'.format(attributes.shape[0],\n",
    "#                                                                                 ', '.join(variables)))\n",
    "\n",
    "# keep reservoirs that comply with the catchment area and total storage conditions\n",
    "if cfg.MIN_AREA is not None:\n",
    "    mask_area = attributes.CATCH_SKM >= cfg.MIN_AREA\n",
    "    attributes = attributes[mask_area]\n",
    "    print('{0} reservoirs comply with the minimum catchment area: {1} km²'.format(attributes.shape[0],\n",
    "                                                                                  cfg.MIN_AREA))\n",
    "if cfg.MIN_VOL is not None:\n",
    "    mask_volume = attributes.CAP_MCM >= cfg.MIN_VOL\n",
    "    attributes = attributes[mask_volume]\n",
    "    print('{0} reservoirs comply with the minimum storage capacity: {1} hm3'.format(attributes.shape[0],\n",
    "                                                                                    cfg.MIN_VOL))\n",
    "\n",
    "if cfg.MIN_DOR is not None:\n",
    "    mask_dor = attributes.DOR >= cfg.MIN_DOR\n",
    "    attributes = attributes[mask_dor]\n",
    "    print('{0} reservoirs comply with the minimum degree of regulation: {1}'.format(attributes.shape[0],\n",
    "                                                                                    cfg.MIN_DOR))\n",
    "\n",
    "if cfg.MIN_DOD is not None:\n",
    "    mask_dod = attributes.DOD_M >= cfg.MIN_DOD\n",
    "    attributes = attributes[mask_dod]\n",
    "    print('{0} reservoirs comply with the minimum degree of disruptivity: {1} m'.format(attributes.shape[0],\n",
    "                                                                                        cfg.MIN_DOD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07a7af-b676-4a54-b2f9-d7f62acf74ae",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3ce9d6-350a-41ad-8345-1097aed7f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 reservoirs with timeseries\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read time series\n",
    "timeseries = read_timeseries(cfg.PATH_TS / 'csv',\n",
    "                             attributes.index)\n",
    "print(f'{len(timeseries)} reservoirs with timeseries\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691a230-50d0-42e8-b1c9-a3fb6bef772f",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53d31c9-1d85-47d9-8dfa-fadefe9ff162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052d78a02f544994becfe535359bb285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "select reservoirs:   0%|          | 0/145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656 discarded for excesive bias:\t0.55\n",
      "2661 discarded for lack of records:\t839 days\n",
      "2699 discarded for excesive bias:\t0.64\n",
      "2812 discarded for excesive bias:\t1.50\n",
      "2821 discarded for excesive bias:\t0.58\n",
      "2824 discarded for excesive bias:\t0.66\n",
      "2833 discarded for excesive bias:\t0.61\n",
      "2839 discarded for excesive bias:\t0.69\n",
      "2855 discarded for excesive bias:\t1.30\n",
      "2866 discarded for excesive bias:\t0.62\n",
      "2878 discarded for excesive bias:\t0.69\n",
      "2880 discarded for excesive bias:\t0.68\n",
      "2895 discarded for excesive bias:\t0.50\n",
      "3504 discarded for excesive bias:\t1.63\n",
      "7052 discarded for excesive bias:\t0.27\n",
      "\n",
      "130 reservoirs selected\n"
     ]
    }
   ],
   "source": [
    "bias = {}\n",
    "periods = {}\n",
    "for grand_id, ts in tqdm(timeseries.items(), desc='select reservoirs', total=len(timeseries)):\n",
    "    \n",
    "    # select study period\n",
    "    start, end = define_period(ts[variables])\n",
    "    if np.isnan(start) or np.isnan(end):\n",
    "        print(f'{grand_id:>4} discarded for lack of records')\n",
    "        continue\n",
    "    duration = (end - start) / np.timedelta64(1, 'D')\n",
    "    if duration >= cfg.MIN_YEARS * 365:\n",
    "        ts = ts.loc[start:end]\n",
    "    else:\n",
    "        print(f'{grand_id:>4} discarded for lack of records:\\t{duration:.0f} days')\n",
    "        continue\n",
    "        \n",
    "    # bias between inflow and outflow\n",
    "    bias[grand_id] = ts.outflow.mean() / ts.inflow.mean()\n",
    "    if (1 - cfg.TOL_BIAS) <= bias[grand_id] <= (1 + cfg.TOL_BIAS):\n",
    "        # save periods\n",
    "        periods[str(grand_id)] = {\n",
    "            'start_dates': [pd.Timestamp(start)],\n",
    "            'end_dates': [pd.Timestamp(end)]\n",
    "        }\n",
    "    else:\n",
    "        print(f'{grand_id:>4} discarded for excesive bias:\\t{bias[grand_id]:.2f}')\n",
    "    \n",
    "print(f'\\n{len(periods)} reservoirs selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219fb1c-1968-4ac0-a1de-ceb5f8ea3b7d",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23409f11-7fd9-47da-abe7-c545f1300f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export list of selected reservoirs\n",
    "with open(PATH_OUT / 'reservoirs.txt', 'w') as f:\n",
    "    for grand_id in periods.keys():\n",
    "        f.write(f'{grand_id}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2333bb16-7bbe-4d9c-a9a2-dfc72b62f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export selected study period\n",
    "with open(PATH_OUT / 'periods_2.pkl', 'wb') as f:\n",
    "    pickle.dump(periods, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50555146-0b5a-4999-902c-fe3a859328c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export shapefile of the selected reservoirs\n",
    "reservoirs = pd.read_csv(cfg.PATH_ATTRS / 'grand.csv', index_col='GRAND_ID')\n",
    "reservoirs = reservoirs.loc[[int(ID) for ID in periods]]\n",
    "geometry = [Point(xy) for xy in zip(reservoirs.LON, reservoirs.LAT)]\n",
    "reservoirs = gpd.GeoDataFrame(reservoirs, geometry=geometry)\n",
    "reservoirs = reservoirs.set_crs(epsg=4326)\n",
    "reservoirs.to_file(PATH_OUT / 'reservoirs.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641ef6c-1124-450c-89c2-3ad491b964e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
