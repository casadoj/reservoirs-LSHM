{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2b7847-f7cc-4aea-9e9a-ad1ec1178fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4726b0-e8a8-4d08-94eb-e248f6e5468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_degrees(string: str) -> float:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return float(string)\n",
    "    except:\n",
    "        aux = string.replace(' ', '')\n",
    "        coords = re.sub(r'[°⁰o′″º°\\'\"¹I,ʼ]', ' ', aux).strip().split(' ')\n",
    "        return np.sum([float(x) / 60**i for i, x in enumerate(coords[:3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d16fded-c1a3-4ac1-8a31-c013a53e9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_KZ = Path('Z:/nahaUsers/casadje/datasets/Kazakhstan/reservoirs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9354fa13-ec0f-4c33-9152-b97f73980ddd",
   "metadata": {},
   "source": [
    "## Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7001db23-485f-449e-8672-e807a42f333c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reservoirs = pd.read_excel(\n",
    "    PATH_KZ / 'reservoirs.xlsx',\n",
    "    sheet_name='processed',\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "rename_cols = {\n",
    "    'Name of the structures': 'RES_NAME',\n",
    "    # 'Branch',\n",
    "    # 'Class',\n",
    "    # 'Water source',\n",
    "    'Year of commissioning': 'YEAR',\n",
    "    'total volume': 'CAP_MCM',\n",
    "    # 'effective volume',\n",
    "    # 'Type of regulation and purpose (long-term, seasonal, standard, liquid)',\n",
    "    # 'Capacity of the facility, m3/s',\n",
    "    # 'Total area, ha',\n",
    "    # 'Mirror area, km2',\n",
    "    # 'Percentage of wear ', \n",
    "    # 'Technical condition', \n",
    "    # 'Paradise center (km)',\n",
    "    # 'The nearest settlement (km)',\n",
    "    'longitude': 'LON',\n",
    "    'latitude': 'LAT',\n",
    "    'Maximum depth according to the project, m': 'DEPTH_M',\n",
    "    # 'The year of acceptance on the balance sheet',\n",
    "    # 'On the balance sheet (specify whose account)'\n",
    "}\n",
    "reservoirs.rename(columns=rename_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2d731d-dc4b-4be6-9db5-8a0055347429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to shapefile\n",
    "reservoirs.LAT = [convert_degrees(lat) for lat in reservoirs.LAT]\n",
    "reservoirs.LON = [convert_degrees(lat) for lat in reservoirs.LON]\n",
    "geometry = [Point(lon, lat) for lon, lat in zip(reservoirs.LON, reservoirs.LAT)]\n",
    "reservoirs = gpd.GeoDataFrame(reservoirs, geometry=geometry).set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f417d5-980b-4477-8260-e6a73fbe1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoirs.to_file(PATH_KZ / 'reservoirs.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4c048-395e-4a09-9c8c-00d9aae43048",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ade4d2b1-758e-4c5c-a1d3-438c17d695b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_header(xls_file, sheet_name=None):\n",
    "    \n",
    "    header = pd.read_excel(file, sheet_name=sheet_name, nrows=2)\n",
    "\n",
    "    years = []\n",
    "    for col in header.columns:\n",
    "        try:\n",
    "            years.append(int(col))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    variables = list(set([col.lower() for col in header.iloc[0, :].values if isinstance(col, str)]))\n",
    "\n",
    "    # name = header.loc[1, 'Name of the reservoir '].split()\n",
    "    \n",
    "    return years, variables#, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cc561896-cad3-40da-952b-857591e59aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('Z:/nahaUsers/casadje/datasets/Kazakhstan/reservoirs/timeseries/raw/Northern Kazakhstan/Northern Kazakhstan.xlsx'),\n",
       " 'Sergeyevsky')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file, res_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c494247c-32ef-4cf5-9f8c-b85afab8d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    years, variables = read_header(file, sheet_name=res_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "699fa15a-b056-46af-99ea-2300dea4cd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['discharge of million m3', 'volume million m3', 'inflow of million m3']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ea80077c-a058-43a5-9206-2e00d9236b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # import time series data\n",
    "    data = pd.read_excel(file, sheet_name=res_name, skiprows=1).iloc[:, 2:]\n",
    "    \n",
    "    # remove empty days\n",
    "    data = data[data.iloc[:, 1].notnull()]\n",
    "\n",
    "    #  create index\n",
    "    data.columns = ['month', 'day'] + data.columns.tolist()[2:]\n",
    "    if data.shape[0] == 366:\n",
    "        idx = pd.date_range(datetime(2000, 1, 1), datetime(2000, 12, 31))\n",
    "    elif data.shape[0] == 365:\n",
    "        idx = pd.date_range(datetime(2001, 1, 1), datetime(2001, 12, 31))\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected shape of data: {data.shape}\")\n",
    "    data.month = idx.month\n",
    "    data.day = idx.day\n",
    "    data.set_index(['month', 'day'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c4eab8c6-6230-45df-992a-9a5d67b33365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    # make sure that all values are float\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            try:\n",
    "                data[col] = data[col].astype(float)\n",
    "            except:\n",
    "                data[col] = data[col].str.replace(',', '.')\n",
    "                # data[col] = data[col].str.replace('..', '.')\n",
    "                data[col].replace(to_replace=r'\\s+', value=np.nan, regex=True, inplace=True)\n",
    "                # data[col] = data[col].replace('', np.nan)\n",
    "                data[col] = data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0524d4b5-a629-44a2-ae8f-ddf9429398cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # reorganise data\n",
    "    dates = pd.date_range(start=datetime(years[0], 1, 1), end=datetime(years[-1], 12, 31))\n",
    "    ts = pd.DataFrame(index=dates, columns=variables)\n",
    "    ts.index.name = 'date'\n",
    "    for y, (year) in enumerate(years):\n",
    "        # select data from that year\n",
    "        icols = list(y * len(variables) + np.arange(len(variables)))\n",
    "        df = data.iloc[:, icols].copy()\n",
    "        df.columns = variables\n",
    "        df = df.astype(float)\n",
    "        # remove February 29 if not leap year\n",
    "        if not calendar.isleap(year) and (df.shape[0] == 366):\n",
    "            df.drop((2, 29), axis=0, inplace=True)\n",
    "        df.index = [datetime(year, month, day) for month, day in df.index]\n",
    "        # save values\n",
    "        ts.loc[df.index, variables] = df[variables].values  \n",
    "        \n",
    "    # keep period with data\n",
    "    start, end = ts[variables].first_valid_index(), ts[variables].last_valid_index()\n",
    "    ts = ts.loc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e97bc207-011f-40fd-ba8d-2526344f1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_timeseries(xls_file, sheet_name=None):\n",
    "    \n",
    "    # read header\n",
    "    years, variables = read_header(xls_file, sheet_name=sheet_name)\n",
    "    \n",
    "    # import time series data\n",
    "    data = pd.read_excel(xls_file, sheet_name=sheet_name, skiprows=1).iloc[:, 2:]\n",
    "    \n",
    "    # remove empty days\n",
    "    data = data[data.iloc[:, 1].notnull()]\n",
    "    \n",
    "    #  create index\n",
    "    data.columns = ['month', 'day'] + data.columns.tolist()[2:]\n",
    "    if data.shape[0] == 366:\n",
    "        idx = pd.date_range(datetime(2000, 1, 1), datetime(2000, 12, 31))\n",
    "    elif data.shape[0] == 365:\n",
    "        idx = pd.date_range(datetime(2001, 1, 1), datetime(2001, 12, 31))\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected shape of data: {data.shape}\")\n",
    "    data.month = idx.month\n",
    "    data.day = idx.day\n",
    "    data.set_index(['month', 'day'], inplace=True)\n",
    "    \n",
    "    # make sure that all values are float\n",
    "    for col in data.columns:\n",
    "        if data[col].dtype == 'object':\n",
    "            try:\n",
    "                data[col] = data[col].astype(float)\n",
    "            except:\n",
    "                data[col].replace(',+', '.', regex=True, inplace=True)\n",
    "                # data[col] = data[col].str.replace('..', '.')\n",
    "                data[col].replace('-', np.nan, inplace=True)\n",
    "                data[col].replace('p', np.nan, inplace=True)\n",
    "                data[col].replace(to_replace=r'\\s+', value=np.nan, regex=True, inplace=True)\n",
    "                data[col] = data[col].astype(float)\n",
    "    \n",
    "    # reorganise data\n",
    "    dates = pd.date_range(start=datetime(years[0], 1, 1), end=datetime(years[-1], 12, 31))\n",
    "    ts = pd.DataFrame(index=dates, columns=variables)\n",
    "    ts.index.name = 'date'\n",
    "    for y, (year) in enumerate(years):\n",
    "        # select data from that year\n",
    "        icols = list(y * len(variables) + np.arange(len(variables)))\n",
    "        df = data.iloc[:, icols].copy()\n",
    "        df.columns = variables\n",
    "        df = df.astype(float)\n",
    "        # remove February 29 if not leap year\n",
    "        if not calendar.isleap(year) and (df.shape[0] == 366):\n",
    "            df.drop((2, 29), axis=0, inplace=True)\n",
    "        df.index = [datetime(year, month, day) for month, day in df.index]\n",
    "        # save values\n",
    "        ts.loc[df.index, variables] = df[variables].values         \n",
    "    \n",
    "    # keep period with data\n",
    "    start, end = ts[variables].first_valid_index(), ts[variables].last_valid_index()\n",
    "    ts = ts.loc[start:end]\n",
    "    \n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "87ffbff5-0f05-43e6-b88a-55007ec9435f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9cb2fe0a3a4e86803accb07eb34a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "basins:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_ts = PATH_KZ / 'timeseries'\n",
    "basins = [item.stem for item in (path_ts / 'raw').iterdir() if item.is_dir()]\n",
    "\n",
    "for basin in tqdm(basins, desc='basins'):\n",
    "    path = path_ts / 'raw' / basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4b8e041c-509c-456a-9fba-faa763ca9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path_ts / 'raw' / 'Zhetysu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d9d55643-aa3b-46ed-870d-1e507cba62b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650393abc4db472aa13b7defda9b1eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reservoirs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-2017\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected shape of data: (97, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [249], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(res_name)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# years, variables, name = read_header(file)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m ts \u001b[38;5;241m=\u001b[39m \u001b[43mread_timeseries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m ts\u001b[38;5;241m.\u001b[39mto_csv(out_file)\n",
      "Cell \u001b[1;32mIn [241], line 19\u001b[0m, in \u001b[0;36mread_timeseries\u001b[1;34m(xls_file, sheet_name)\u001b[0m\n\u001b[0;32m     17\u001b[0m     idx \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(datetime(\u001b[38;5;241m2001\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), datetime(\u001b[38;5;241m2001\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m31\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected shape of data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m data\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     21\u001b[0m data\u001b[38;5;241m.\u001b[39mday \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mday\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected shape of data: (97, 10)"
     ]
    }
   ],
   "source": [
    "    files = path.glob('*.xlsx')\n",
    "    for file in tqdm(files, desc='reservoirs'):\n",
    "        data_dct = pd.read_excel(file, sheet_name=None)\n",
    "        for res_name in data_dct.keys():\n",
    "\n",
    "            # res_name = file.stem.split()[0]\n",
    "\n",
    "            out_file = path_ts / 'processed' / f'{res_name.lower()}.csv'\n",
    "            if out_file.is_file():\n",
    "                continue\n",
    "            print(res_name)\n",
    "\n",
    "            # years, variables, name = read_header(file)\n",
    "            ts = read_timeseries(file, sheet_name=res_name)\n",
    "            ts.to_csv(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d87aa-2579-4a7b-a2c8-dd7233c1c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e4bdc-1c8b-4e43-9fce-0a768276b9a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
